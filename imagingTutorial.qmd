---
title: "Neuroimage handling tutorial"
---

## Overview

This is a brief preview of neuroimage I/O, manipulation, and analysis for `R` taught as a segment of the "Introduction to neuroimage analysis for biostatisticians" short course for the International Chinese Statistical Association 2024 conference.

## R package dependencies


Most `R` neuroimaging packages are hosted on [Neuroconductor](https://neuroconductor.org/) We use the following packages (alphabetically listed):

* `papayaWidget` - embedded interactive visualization of Nifti images in html documents.
* `pbj` - Parametric bootstrap joint inference for testing in neuroimaging data. Contains visualization functions for `niftiImage` objects.
* `PCP`  - [Preprocessed connectomes project](https://preprocessed-connectomes-project.org/abide) package. Contains `downloadABIDE` function to get open-access imaging data from the Autism Brain Imaging Data Exchange.
* `RNifti` - Nifti Image I/O.

The following two code chunks install packages if needed and load all the packages required for the tutorial.

```{r packageList}
# data frame of packages used in tutorial
packages = data.frame(
  packages = c('devtools', 'papayaWidget', 'PCP', 'RNifti', 'fslr'),
  repos = c('cran', 'nc', 'statimagcoll/PCP', 'nc', 'nc'))
inds = which(!packages$packages %in% installed.packages()[,"Package"])
```


```{r install, eval=FALSE}
# neuroconductor installer
source("https://neuroconductor.org/neurocLite.R")

for(ind in inds){
  repo = packages$repos[ind]
  package=packages$packages[ind]
  if(repo=='cran'){
    install.packages(package)
  } else if(repo=='nc'){
    neuro_install(package)
  } else {
    devtools::install_github(repo)
  }
}
```


```{r loadPackages, message=FALSE}
devtools::install_github('statimagcoll/PCP')
invisible(sapply(packages$packages, library, character.only=TRUE))
```

## Loading and visualizing data using `downloadABIDE`

The `PCP::downloadABIDE` function has many options to download preprocessed imaging data in the various modalities  and formats discussed in this course. Here, we will download and visualize several types of data:

* Cortical volumes from [Freesurfer](https://surfer.nmr.mgh.harvard.edu/).
* Network connectivity data.
* [fALFF](https://www.sciencedirect.com/science/article/abs/pii/S0165027008002458) voxel-level data in Nifti image format.

For visualizations, there are many quality checks we might make before analyzing the data.


```{r}
### DATA LOCATION ###
datadir = dirname(tempdir())

# will be created by downloadABIDE
templatefile = file.path(datadir, 'abide/neuroimaging/MNI152_T1_3mm.nii.gz')
```


### Freesurfer cortical volumes

### Network connectivity data

### fALFF voxel-level data


```{r fALFFdownload, message=FALSE}
derivative='falff'

#gcc -I"/usr/share/R/include" -DNDEBUG       -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-E8saoI/r-base-4.3.2=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c pbj.c -o pbj.o

# clang -arch arm64 -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c pbj.c -o pbj.o

# load in data and get directories
dat = ABIDE(datadir, derivatives=derivative, force=FALSE)
# downloads in parallel
# dat = ABIDE(datadir, derivatives=derivative, force=TRUE, mc.cores=4)
head(dat$destfile_falff)
```


### Visual QC

```{r}

```


## Preprocessing and image manipulation



### fALFF mask creation

This excludes participants who have bad coverage. Given the visual quality check in the previous step, this will lean toward excluding subjects with bad image orientation.

```{r maskCreation}
imgs = simplify2array(readNifti(dat$destfile_falff) )
# choose
# number of people with zeros at that location
inds=numeric()
ids = c()
subids = dat$sub_id
# number of voxels with no zeros
nnzero = 0
# iteratively removes subjects who will increase the mask the largest
while(nnzero<30000){
  voxSums = rowSums(imgs==0, dims=3)
  tab = as.data.frame(table(voxSums))
  
  nnzero=tab[1,2]
  # number of unique voxels for each subject
  uniquevox = apply(imgs, 4, function(img) sum(img==0 & voxSums==1) )
  # number of subjects to remove based on those subjects decreasing the amount of unique zero voxels by 50%
  inds = which.max(uniquevox)
  cat('\nIteration:\nsubject removed: ', paste(subids[inds], collapse=', '), '\nmask size is now ', nnzero+sum(uniquevox[inds]), '\nNumber of voxels added:', sum(uniquevox[inds]) )
  imgs = imgs[,,,-inds]
  subids = subids[-inds]
  nnzero=nnzero+sum(uniquevox[inds])
}
```



```{r}
# subset the dataset to the participants we didn't exclude due to coverage
dat = dat[ dat$sub_id %in% subids,]

# now create the mask
# load in the first image. We'll replace all values to make the mask
mask = readNifti(dat$destfile_falff[1])
# clear all values in the mask
mask[,,] = 0
# load in all the data again
imgs = simplify2array(readNifti(dat$destfile_falff) )
# mask is where every subject has coverage
mask[,,] = apply(imgs>0, 1:3, all)
writeNifti(mask, maskfile)
nvox = sum(mask)
# get 90th quantile, which we can use for visualization
ulimit = quantile(apply(imgs, 4, function(x) x[mask!=0]), 0.9)
```


```{r}
# hardcoded at 90 percentile
ulimit = 126.95
niftis = readNifti(dat$destfile_falff)

# base R for visualization
par(mfrow=c(2,5), mar=c(0,0,2,0))
# pbj:::image for pbj:::image.niftiImage
# index - slice to visualize
# lo - use "layout" to arrange images?
# limits - bounds for coloring below lower limit is transparent, above is more yellow (or brightest color)
invisible(lapply(1:length(niftis), function(ind) {image(niftis[[ind]], index=45, lo=FALSE, limits=c(0,ulimit)); mtext(dat$sub_id[ind], outer=FALSE)} ) )
```

